# ü§ü Arabic Sign Language Real-Time Recognition
This project is part of my graduation project at Misr University for Science and Technology (MUST). It implements a real-time Arabic sign language recognition system by loading a CNN-based AI model on live camera input.

# üéØ Project Overview
Goal: Recognize Arabic sign language gestures in real time using a webcam.

Model: A CNN model based on ResNet architecture trained to classify Arabic sign language characters.

Detection: Uses MediaPipe to detect and track hand landmarks.

Integration: The AI model processes MediaPipe hand landmarks and predicts the corresponding sign.

Deployment: The project is deployed via a Flex API backend for seamless integration.

# ‚ú® Features
Real-time detection and classification of hand signs.

Uses MediaPipe for accurate hand landmark detection.

Integrates TensorFlow-based CNN model for sign recognition.

User-friendly interface with live camera input.

Flexible deployment using Flex API.

# üõ†Ô∏è Technologies Used
TensorFlow (for CNN model)

MediaPipe (hand tracking)

OpenCV (camera capture & image processing)

Flex API (backend deployment)

JavaScript / Python (depending on implementation)

# ‚ö° How It Works
The webcam captures live video.

MediaPipe detects hand landmarks from the video feed.

The detected landmarks are fed into the CNN model.

The model classifies the sign and displays the predicted character on screen.

# üôè Acknowledgments
Supervised by Dr. Khaled Alsheshtawi, who provided invaluable guidance and support.

Inspired by Sustainable Development Goals: Quality Education and Reduced Inequalities.



https://github.com/user-attachments/assets/8340c060-ddfc-460f-9f8b-3ca177b20589


